<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>WaylonWalker</title><link href="www.waylonwalker.com/blog/" rel="alternate"></link><link href="www.waylonwalker.com/blog/feeds/all.atom.xml" rel="self"></link><id>www.waylonwalker.com/blog/</id><updated>2017-09-16T00:00:00-05:00</updated><entry><title>background tasks in python</title><link href="www.waylonwalker.com/blog/background-tasks-in-python.html" rel="alternate"></link><published>2017-09-16T00:00:00-05:00</published><updated>2017-09-16T00:00:00-05:00</updated><author><name>Waylon Walker</name></author><id>tag:None,2017-09-16:www.waylonwalker.com/blog/background-tasks-in-python.html</id><summary type="html">&lt;h1&gt;background tasks in python&lt;/h1&gt;
&lt;p&gt;I have tried most of the different methods in the past and found that copying and pasting the &lt;a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example"&gt;threadpoolexecutor example&lt;/a&gt; or the &lt;a href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor-example"&gt;processpoolexecutor example&lt;/a&gt; from the standard library documentation to be the most reliable.  Since this is often something that I stuff in the back of â€¦&lt;/p&gt;</summary><content type="html">&lt;h1&gt;background tasks in python&lt;/h1&gt;
&lt;p&gt;I have tried most of the different methods in the past and found that copying and pasting the &lt;a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example"&gt;threadpoolexecutor example&lt;/a&gt; or the &lt;a href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor-example"&gt;processpoolexecutor example&lt;/a&gt; from the standard library documentation to be the most reliable.  Since this is often something that I stuff in the back of a utility module of a library it is not something that I write often enough to be familiar with, which makes it both hard to write and hard to read and debug.  If you are looking for a good overview of the difference concurrency &lt;a href="https://twitter.com/raymondh"&gt;Raymond Hettinger&lt;/a&gt; has a great talk about the difference between the various different methods, when to use them and why.&lt;/p&gt;
&lt;p&gt;Recently a new python library was released to make running tasks in the background very simple. The &lt;a href="https://github.com/kennethreitz/background"&gt;background&lt;/a&gt; project by Kenneth Reitz is a high level implementation of python 3's ThreadPoolExecutor.  I have been playing around with this project over the last week and I will say that this is definitely the simplest way to run background tasks in python by far.  It really simplifes the syntax and lets me focus on my job rather than implementing custom concurrent code that is more difficult to debug.&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;I have pulled the latest version of the project in Sept 2017.  I found that it had some updates that were important to pass *args and **kwargs compared to the pypi version.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;background&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;bg&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;load_ext&lt;/span&gt; &lt;span class="n"&gt;watermark&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;watermark&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="n"&gt;background&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;2017-09-16

CPython 3.6.2
IPython 6.1.0

background n
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Define Worker Functions&lt;/h2&gt;
&lt;p&gt;Each of these worker functions takes 1s to run, simulating a moderately long calculation that we need to do many times over.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;work&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="nd"&gt;@bg.task&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bg_work&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Run the Worker Functions&lt;/h2&gt;
&lt;h2&gt;Blocking function&lt;/h2&gt;
&lt;p&gt;This function is blocking each time the function runs, thus taking 1 second to run for each calculation.  The example below took exactly &lt;strong&gt;100 s&lt;/strong&gt; to run 100 calculations.  Depending on your use case this may not be fast enough.  If the calculations do not rely on the global state&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;work&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Wall time: 1min 40s
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Reaction&lt;/h3&gt;
&lt;p&gt;I  know what half of you are saying to yourselfs..&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;!!What!! that took 100 s, by now my users have already sent a dozen messages and filed an issue that my feature is down&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and the other half&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Seriously that wasnt even enough time to grab a coffee.  Any real time consuming analysis takes at least 3 dats 14 hours 159 seconds before I start to care about concurrency&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To you I say... I am impatient and I got other things to do rather than wait on this maching to finish its work.  Let's get into this concurrency stuff.&lt;/p&gt;
&lt;h2&gt;Background Function&lt;/h2&gt;
&lt;p&gt;This function spins off worker processes and runs much faster.  By default background sets the number of processes to the number of cpu cores available, Therefore this function should run in n/4 + (inefficiency).  Here we see that the result is just over &lt;strong&gt;13 s&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Note:&lt;em&gt;Since there is a bit of inefficiency added by needing to handle all of the threads it is not exactly divided by the number of workers.&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;
&lt;span class="n"&gt;f_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bg_work&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)];&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;f_list&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Wall time: 13.1 s
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Reaction&lt;/h3&gt;
&lt;p&gt;I know what your saying this time.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;really a 7.6x improvement...  Is that really even woth the extra work.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Fine then lets crank it up to 11!&lt;/p&gt;
&lt;h3&gt;Lots of Background&lt;/h3&gt;
&lt;p&gt;lets set the number of background processes to a value just higher to than the number of workers we need to run in order to start them all simultaneously. With this simple example that is not very CPU intensive we see the result is just over the amount of time that it takes to run 1 worker. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;110&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;
&lt;span class="n"&gt;f_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bg_work&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)];&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;f_list&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Wall time: 1.09 s
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Reaction&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;91x improvement by putting my calculations into a function, adding a decorator, and some checks, im in.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;On Tap&lt;/h2&gt;
&lt;p&gt;This week while taking it up to 11 I was enjoying a super thick and rich cup of El Salvador Finca Rosa from Onyx Coffee Labs.  Check out their love for letting the bean speak for it self and producing a great cup.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://onyxcoffeelab.com"&gt;&lt;img src="https://cdn.shopify.com/s/files/1/1707/3261/files/coffee_science.png?5305428688827820856"&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="Python"></category><category term="Data Science"></category></entry><entry><title>Pycon 2017 Roundup</title><link href="www.waylonwalker.com/blog/pycon-2017-roundup.html" rel="alternate"></link><published>2017-05-30T00:00:00-05:00</published><updated>2017-05-30T00:00:00-05:00</updated><author><name>Waylon Walker</name></author><id>tag:None,2017-05-30:www.waylonwalker.com/blog/pycon-2017-roundup.html</id><summary type="html">&lt;h1&gt;Pycon 2017 Roundup&lt;/h1&gt;
&lt;p&gt;Good afternoon fellow Data Geeks.  Last week &lt;a href="https://www.youtube.com/channel/UCrJhliKNQ8g0qoE_zvL8eVg"&gt;Pycon&lt;/a&gt; released 141 videos of greatness.  Here are my top picks from the event.&lt;/p&gt;
&lt;h2&gt;#3 Kelsey Hightower - Keynote - Pycon 2017&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=u_iAXzy3xBA&amp;amp;t=1795s" title="Click to Watch"&gt;&lt;img alt="Click to Watch" src="http://img.youtube.com/vi/u_iAXzy3xBA/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;#2 Al Sweigart Yes, It's Time to Learn Regular Expressions PyCon 2017&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=abrcJ9MpF60" title="Click to Watch"&gt;&lt;img alt="Click to Watch" src="http://img.youtube.com/vi/abrcJ9MpF60/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;#1 Trey Hunner Readability Counts PyCon 2017&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=knMg6G9_XCg" title="Click to Watch"&gt;&lt;img alt="Click to Watch" src="http://img.youtube.com/vi/knMg6G9_XCg/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What's â€¦&lt;/h2&gt;</summary><content type="html">&lt;h1&gt;Pycon 2017 Roundup&lt;/h1&gt;
&lt;p&gt;Good afternoon fellow Data Geeks.  Last week &lt;a href="https://www.youtube.com/channel/UCrJhliKNQ8g0qoE_zvL8eVg"&gt;Pycon&lt;/a&gt; released 141 videos of greatness.  Here are my top picks from the event.&lt;/p&gt;
&lt;h2&gt;#3 Kelsey Hightower - Keynote - Pycon 2017&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=u_iAXzy3xBA&amp;amp;t=1795s" title="Click to Watch"&gt;&lt;img alt="Click to Watch" src="http://img.youtube.com/vi/u_iAXzy3xBA/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;#2 Al Sweigart Yes, It's Time to Learn Regular Expressions PyCon 2017&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=abrcJ9MpF60" title="Click to Watch"&gt;&lt;img alt="Click to Watch" src="http://img.youtube.com/vi/abrcJ9MpF60/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;#1 Trey Hunner Readability Counts PyCon 2017&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=knMg6G9_XCg" title="Click to Watch"&gt;&lt;img alt="Click to Watch" src="http://img.youtube.com/vi/knMg6G9_XCg/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What's on Tap&lt;/h2&gt;
&lt;p&gt;This afternoon we have a cup of from one of my favorite roasters Thirty Thiry Coffee.  This &lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.thirty-thirtycoffee.com/" title="Whats on Tap"&gt;&lt;img alt="Whats on Tap" src="http://www.thirty-thirtycoffee.com/wp-content/uploads/2016/09/thirty-thirty-peoria-logo.png"&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="Python"></category><category term="Pycon"></category><category term="Youtube"></category></entry></feed>